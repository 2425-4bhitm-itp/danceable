{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc7a8c0",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad37b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Principal Component Analysis (PCA)\n",
    "\n",
    "Principal Component Analysis (PCA) is a dimensionality reduction technique used to simplify complex datasets while preserving as much variance (information) as possible.  \n",
    "It works by finding new axes, called **principal components (PCs)**, which represent directions of maximum variance in the data. These components are linear combinations of the original features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9927cd56",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How PCA Works\n",
    "1. The data is standardized (mean-centered and scaled).\n",
    "2. PCA computes the covariance matrix and extracts its eigenvectors and eigenvalues.\n",
    "3. The eigenvectors define the new axes (principal components), and the eigenvalues indicate how much variance each axis explains.\n",
    "4. The data is then projected onto these new components to obtain lower-dimensional representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f44a7fa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Interpretation of PC1 and PC2\n",
    "- **PC1 (Principal Component 1)**  \n",
    "  The first principal component captures the **largest amount of variance** in the dataset. It represents the most dominant underlying pattern across all features.  \n",
    "  For example, if your mel features dominate PC1, it means that variations in the mel spectrum are the primary source of difference between samples.\n",
    "\n",
    "- **PC2 (Principal Component 2)**  \n",
    "  The second component captures the **next largest amount of variance** that is **orthogonal** (independent) to PC1.  \n",
    "  It often reveals secondary patterns or contrasts that PC1 cannot describe, such as variations related to rhythm or timbre when analyzing audio."
   ]
  },
  {
   "cell_type": "code",
   "id": "6aba527a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"features_renamed.csv\")\n",
    "\n",
    "label_col = \"label\"  # adjust if needed\n",
    "\n",
    "# --- select numeric feature columns ---\n",
    "numeric_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "if label_col in numeric_cols:\n",
    "    numeric_cols.remove(label_col)\n",
    "\n",
    "X = df[numeric_cols].values\n",
    "\n",
    "# --- scale numeric features ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- perform PCA ---\n",
    "n_components = 10\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# --- explained variance summary ---\n",
    "explained = pca.explained_variance_ratio_\n",
    "cum_explained = np.cumsum(explained)\n",
    "\n",
    "print(\"\\n=== PCA EXPLAINED VARIANCE ===\")\n",
    "for i, var in enumerate(explained, start=1):\n",
    "    print(f\"PC{i:>2}: {var*100:6.2f}% (cumulative {cum_explained[i-1]*100:6.2f}%)\")\n",
    "\n",
    "# --- feature loadings (influence per original variable) ---\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    columns=[f\"PC{i+1}\" for i in range(n_components)],\n",
    "    index=numeric_cols\n",
    ")\n",
    "\n",
    "# show top contributing features for PC1 and PC2\n",
    "print(\"\\n=== TOP 10 FEATURES CONTRIBUTING TO PC1 ===\")\n",
    "print(loadings[\"PC1\"].abs().sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\n=== TOP 10 FEATURES CONTRIBUTING TO PC2 ===\")\n",
    "print(loadings[\"PC2\"].abs().sort_values(ascending=False).head(10))\n",
    "\n",
    "# --- optional: aggregate variance by feature group prefix ---\n",
    "group_prefixes = [\"mfcc_\", \"chroma_\", \"mel_\", \"contrast_\", \"tonnetz_\"]\n",
    "group_contrib = {}\n",
    "\n",
    "for prefix in group_prefixes:\n",
    "    cols = [c for c in numeric_cols if c.startswith(prefix)]\n",
    "    if cols:\n",
    "        total = loadings.loc[cols, \"PC1\"].abs().sum() + loadings.loc[cols, \"PC2\"].abs().sum()\n",
    "        group_contrib[prefix.rstrip(\"_\")] = total\n",
    "\n",
    "if group_contrib:\n",
    "    print(\"\\n=== GROUP CONTRIBUTIONS (|loadings| summed over PC1+PC2) ===\")\n",
    "    for g, val in sorted(group_contrib.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{g:10s}: {val:.4f}\")\n",
    "\n",
    "# --- per-label mean PCA coordinates (for cluster separation insight) ---\n",
    "if label_col in df.columns:\n",
    "    pca_df = pd.DataFrame(X_pca[:, :2], columns=[\"PC1\", \"PC2\"])\n",
    "    pca_df[label_col] = df[label_col]\n",
    "    print(\"\\n=== PCA MEANS PER LABEL (first 2 PCs) ===\")\n",
    "    print(pca_df.groupby(label_col)[[\"PC1\", \"PC2\"]].mean())\n",
    "    \n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "20866d57",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Explained variance\n",
    "\n",
    "| Component | Variance (%) | Cumulative (%) |\n",
    "| --------- | ------------ | -------------- |\n",
    "| PC1       | 11.41        | 11.41          |\n",
    "| PC2       | 5.08         | 16.49          |\n",
    "| PC3       | 4.41         | 20.91          |\n",
    "| PC4–PC10  | each ≈2–3    | 35.64 total    |\n",
    "\n",
    "## Interpretation:\n",
    "\n",
    "- The first principal component explains **~11 % of total variance**, and the first 10 components together explain **only ~36 %**.\n",
    "\n",
    "- That means your dataset’s variance is spread across many orthogonal directions — **it’s highly complex and non‐redundant**.\n",
    "\n",
    "- This is typical for **audio embeddings** (e.g. Mel and MFCCs) because each coefficient captures distinct spectral information.\n",
    "\n",
    "- So: there is **no dominant single low‐dimensional structure**; class separations are likely subtle and nonlinear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a6fbce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# 2. Feature loadings (which features drive the variance)\n",
    "\n",
    "**PC1 dominated by Mel features**\n",
    "`mel_105–116` are the strongest contributors.\n",
    "These are middle–high Mel filter bands.\n",
    "Interpretation:\n",
    "→ The first principal axis mostly measures overall energy/variance in the **Mel spectrogram region**, not rhythm or timbre directly.\n",
    "\n",
    "**PC2 mixes MFCC and Mel + some Contrast**\n",
    "Top features include:\n",
    "\n",
    "- `mfcc_3 (a spectral shape coefficient, roughly spectral slope/brightness)\n",
    "\n",
    "- several `mel_6x–7x` filters (lower–mid band energy)\n",
    "\n",
    "- and `contrast_4`, `contrast_5` (spectral contrast between peaks/valleys)\n",
    "\n",
    "Interpretation:\n",
    "→ The second component represents a blend of **spectral shape + low–mid Mel energy**, possibly correlating with timbral brightness or instrumentation differences between dance styles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d62cfae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Group contribution summary\n",
    "\n",
    "| Group    | Combined absolute loadings (PC1+PC2) | Relative importance     |\n",
    "| -------- | ------------------------------------ | ----------------------- |\n",
    "| **Mel**  | 24.42                                | overwhelmingly dominant |\n",
    "| MFCC     | 1.81                                 | minor                   |\n",
    "| Chroma   | 1.38                                 | small                   |\n",
    "| Contrast | 1.17                                 | small                   |\n",
    "| Tonnetz  | 0.55                                 | smallest                |\n",
    "\n",
    "\n",
    "## Interpretation:\n",
    "\n",
    "- The **Mel features dominate** your dataset’s global variance; most variation comes from raw spectral energy distribution, not high‐level harmonic descriptors.\n",
    "\n",
    "- MFCC, Chroma, Contrast, and Tonnetz are much smaller contributors to the first two variance directions.\n",
    "\n",
    "- This doesn’t mean they’re unimportant for classification — only that they vary less globally across the dataset. In fact, those smaller groups might encode class‐specific cues that PCA (being unsupervised) doesn’t emphasize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa8a15d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. Label separation in PCA space\n",
    "\n",
    "Mean coordinates:\n",
    "\n",
    "| Label       | PC1   | PC2   |\n",
    "| ----------- | ----- | ----- |\n",
    "| discofox    | 2.15  | 1.70  |\n",
    "| jive        | 2.01  | 0.11  |\n",
    "| samba       | 0.48  | 2.38  |\n",
    "| chacha      | 0.82  | 0.84  |\n",
    "| salsa       | 0.72  | -1.31 |\n",
    "| rumba       | -0.87 | -0.71 |\n",
    "| foxtrott    | 0.10  | 0.17  |\n",
    "| quickstep   | -0.21 | -0.38 |\n",
    "| viennawaltz | -2.19 | -1.46 |\n",
    "| slowwaltz   | -6.21 | -2.99 |\n",
    "\n",
    "\n",
    "## Interpretation:\n",
    "\n",
    "- Clear gradient along PC1:\n",
    "\n",
    "    - **Positive side (high PC1)** → upbeat, rhythmically strong dances (discofox, jive, samba, chacha).\n",
    "\n",
    "    - **Negative side (low PC1)** → slower, smoother waltzes.\n",
    "    → PC1 seems to correspond to tempo or rhythmic energy.\n",
    "\n",
    "- PC2 separates some Latin styles (samba high, salsa low) and shows secondary contrast likely tied to **timbre or instrumentation density**.\n",
    "\n",
    "- So PCA actually captures musical style structure reasonably well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dff324",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5. Summary of what this tells you\n",
    "\n",
    "| Aspect                 | Observation                               | Implication                                                                 |\n",
    "| ---------------------- | ----------------------------------------- | --------------------------------------------------------------------------- |\n",
    "| Variance distribution  | Highly spread; no few components dominate | Deep models will need many latent factors                                   |\n",
    "| Dominant feature group | Mel features                              | Ensure Mel scaling/normalization is appropriate; consider balancing         |\n",
    "| Class structure        | Visible grouping by tempo/energy          | PCA captures meaningful musical axis                                        |\n",
    "| PCA as preprocessing   | Not ideal for deep learning input         | Use raw standardized features; let the network learn nonlinear combinations |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c338810459be4cc9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "1fd3a0985e1b8013",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "66e0a820c4231a6b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Group Data by Label"
   ]
  },
  {
   "cell_type": "code",
   "id": "fe5e4760326dc62d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "df = pd.read_csv('features.csv')\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in [\"filename\", \"label\"]]\n",
    "\n",
    "feature_groups = {\n",
    "        \"mfcc\": [c for c in feature_cols if c.startswith(\"mfcc_\")],\n",
    "        \"chroma\": [c for c in feature_cols if c.startswith(\"chroma_\")],\n",
    "        \"mel\": [c for c in feature_cols if c.startswith(\"mel_\")],\n",
    "        \"contrast\": [c for c in feature_cols if c.startswith(\"contrast_\")],\n",
    "        \"tonnetz\": [c for c in feature_cols if c.startswith(\"tonnetz_\")],\n",
    "        \"tempogram\": [c for c in feature_cols if c.startswith(\"tempogram_\")],\n",
    "        \"rms\": [c for c in feature_cols if c.startswith(\"rms_\")],\n",
    "        \"spectral_flux\": [c for c in feature_cols if c.startswith(\"spectral_flux_\")],\n",
    "        \"onset\": [c for c in feature_cols if c.startswith(\"onset_strength_\")],\n",
    "        \"tempo\": [c for c in feature_cols if c == \"tempo_bpm\"],\n",
    "}\n",
    "\n",
    "target_col = \"label\" if \"label\" in df.columns else None\n",
    "\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\")\n",
    "\n",
    "if target_col is None:\n",
    "    raise ValueError(\"No 'label' column found in dataset.\")\n",
    "feature_groups"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5f84637ff83c71cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualization Grid"
   ]
  },
  {
   "cell_type": "code",
   "id": "d579d1b15219725a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "for name, cols in feature_groups.items():\n",
    "    if len(cols) == 0:\n",
    "        print(f\"Skipping {name}: No columns found.\")\n",
    "        continue\n",
    "\n",
    "    X_group = df[cols].to_numpy()\n",
    "    n_features = X_group.shape[1]\n",
    "\n",
    "    # Case 1: PCA possible (two or more features)\n",
    "    if n_features >= 2:\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X_group)\n",
    "        df_plot = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
    "        df_plot['label'] = df[target_col]\n",
    "\n",
    "        fig = plt.figure(figsize=(18, 10))\n",
    "        fig.suptitle(f\"PCA Visualization for {name} Features\", fontsize=18, y=1.02)\n",
    "\n",
    "        # Boxplots\n",
    "        ax1 = plt.subplot2grid((2, 3), (0, 0))\n",
    "        sns.boxplot(x='label', y='PC1', data=df_plot, ax=ax1)\n",
    "        ax1.set_title('Boxplot of PC1')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "        ax2 = plt.subplot2grid((2, 3), (0, 1))\n",
    "        sns.boxplot(x='label', y='PC2', data=df_plot, ax=ax2)\n",
    "        ax2.set_title('Boxplot of PC2')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # Histograms\n",
    "        ax3 = plt.subplot2grid((2, 3), (0, 2))\n",
    "        sns.histplot(data=df_plot, x=\"PC1\", hue=\"label\", bins=30, kde=True, element=\"step\", ax=ax3)\n",
    "        ax3.set_title('Histogram of PC1')\n",
    "\n",
    "        ax4 = plt.subplot2grid((2, 3), (1, 0))\n",
    "        sns.histplot(data=df_plot, x=\"PC2\", hue=\"label\", bins=30, kde=True, element=\"step\", ax=ax4)\n",
    "        ax4.set_title('Histogram of PC2')\n",
    "\n",
    "        # Scatter\n",
    "        ax5 = plt.subplot2grid((2, 3), (1, 1), colspan=2)\n",
    "        sns.scatterplot(x='PC1', y='PC2', data=df_plot,\n",
    "                        hue='label', palette=\"tab10\", ax=ax5)\n",
    "        ax5.set_title(f'Scatter Plot (PC1 vs PC2): {name} Features')\n",
    "        ax5.legend(title=\"Label\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        continue\n",
    "\n",
    "    # Case 2: Single feature (e.g., BPM)\n",
    "    if n_features == 1:\n",
    "        feature = cols[0]\n",
    "        df_plot = pd.DataFrame({\n",
    "            \"value\": df[feature],\n",
    "            \"label\": df[target_col]\n",
    "        })\n",
    "\n",
    "        fig = plt.figure(figsize=(18, 10))\n",
    "        fig.suptitle(f\"Single Feature Visualization for {name} ({feature})\", fontsize=18, y=1.02)\n",
    "\n",
    "        # Boxplot\n",
    "        ax1 = plt.subplot2grid((2, 3), (0, 0))\n",
    "        sns.boxplot(x=\"label\", y=\"value\", data=df_plot, ax=ax1)\n",
    "        ax1.set_title(f\"Boxplot of {feature}\")\n",
    "        ax1.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "        # Histogram\n",
    "        ax2 = plt.subplot2grid((2, 3), (0, 1))\n",
    "        sns.histplot(data=df_plot, x=\"value\", hue=\"label\", bins=30,\n",
    "                     kde=True, element=\"step\", ax=ax2)\n",
    "        ax2.set_title(f\"Histogram of {feature}\")\n",
    "\n",
    "        # Scatter not meaningful → replace with stripplot\n",
    "        ax3 = plt.subplot2grid((2, 3), (1, 0), colspan=2)\n",
    "        sns.stripplot(x=\"label\", y=\"value\", data=df_plot, ax=ax3, jitter=0.2)\n",
    "        ax3.set_title(f\"Distribution by Label: {feature}\")\n",
    "        ax3.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eb21f2d5",
   "metadata": {},
   "source": [
    "combined_pca = pd.DataFrame()\n",
    "combined_pca[target_col] = df[target_col]\n",
    "\n",
    "# Perform PCA for each feature group\n",
    "for name, cols in feature_groups.items():\n",
    "    if len(cols) == 0:\n",
    "        print(f\"Skipping {name}: No columns found.\")\n",
    "        continue\n",
    "\n",
    "    X_group = df[cols].to_numpy()\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_group)\n",
    "\n",
    "    # Add to combined DataFrame\n",
    "    combined_pca[f\"{name}_PC1\"] = X_pca[:, 0]\n",
    "    combined_pca[f\"{name}_PC2\"] = X_pca[:, 1]\n",
    "\n",
    "# Generate pairplot for all PC components\n",
    "selected_cols = [col for col in combined_pca.columns if col != target_col]\n",
    "\n",
    "g = sns.pairplot(\n",
    "    combined_pca,\n",
    "    vars=selected_cols,\n",
    "    hue=target_col,\n",
    "    diag_kind=\"kde\",\n",
    "    palette=\"tab10\",\n",
    "    corner=True,                  # shows only lower triangle for clarity\n",
    "    plot_kws=dict(alpha=0.6, s=35, edgecolor=\"none\")\n",
    ")\n",
    "\n",
    "g.fig.suptitle(\"Combined PCA Pairplot Across All Parent Feature Groups\", fontsize=18, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "danceable",
   "language": "python",
   "name": "danceable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "rise": {
   "theme": "night"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
