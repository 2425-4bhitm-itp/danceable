{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train Song Classification Model\n",
    "\n",
    "This notebook demonstrates the complete workflow to train a deep learning model to classify songs based on audio features. It includes data preprocessing, model construction, training, evaluation, and deployment-ready export to CoreML.\n",
    "\n",
    "Make sure that the `features.csv` file is available in the specified path, containing pre-extracted audio features and corresponding labels."
   ],
   "id": "6955a916fd4a77a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Imports and Dependencies\n",
    "\n",
    "This section imports all required libraries. TensorFlow/Keras is used for model building, `scikit-learn` for preprocessing and dataset splitting, `joblib` for saving scalers, `pandas` for data handling, and `coremltools` for CoreML conversion."
   ],
   "id": "6f336f9268d9280c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68953077b9a41b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import json\n",
    "import coremltools as ct\n",
    "import os\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## File Paths\n",
    "\n",
    "Define all file paths used in the project for model storage, scaler, label mapping, CoreML export, and the feature CSV. Centralized paths make the notebook easier to maintain and portable across environments."
   ],
   "id": "2b079d884ec81a47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5bd850b5e3ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/app/song-storage/model.keras\"\n",
    "SCALER_PATH = \"/app/song-storage/scaler.pkl\"\n",
    "LABELS_PATH = \"/app/song-storage/label_order.json\"\n",
    "COREML_PATH = \"/app/song-storage/model.mlmodel\"\n",
    "FEATURES_CSV = \"/app/song-storage/features.csv\"\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load Dataset\n",
    "\n",
    "We load the CSV file containing pre-extracted audio features.\n",
    "\n",
    "- `feature_columns` are all columns except `\"filename\"` and `\"label\"`.\n",
    "\n",
    "- `X` contains the feature vectors and `y` the categorical labels.\n",
    "\n",
    "Printing shapes confirms the dataset dimensions and ensures proper loading."
   ],
   "id": "f5075c29d82f624"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e51a6ea2700254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FEATURES_CSV)\n",
    "feature_columns = [col for col in df.columns if col not in [\"filename\", \"label\"]]\n",
    "X = df[feature_columns].values\n",
    "y = df[\"label\"].values\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Standardize Features\n",
    "\n",
    "Normalization is crucial for deep learning convergence.\n",
    "We use `StandardScaler` to standardize features to zero mean and unit variance.\n",
    "The scaler is saved using `joblib` to ensure the same transformation can be applied at inference time."
   ],
   "id": "625ba351dc4c95cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43f1ecf7522aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, SCALER_PATH)\n",
    "print(\"Scaler saved.\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Encode Labels\n",
    "\n",
    "Convert categorical string labels into one-hot encoded vectors.\n",
    "This allows the model to output probabilities across multiple dance classes.\n",
    "We also save a `label_to_index` mapping for consistent label decoding."
   ],
   "id": "937ed739493f2056"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a67411f0b54c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = sorted(df[\"label\"].unique())\n",
    "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "y = to_categorical([label_to_index[label] for label in y], num_classes=len(unique_labels))\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Split Dataset\n",
    "\n",
    "Split data into training and test sets using an 80/20 split.\n",
    "This allows evaluation of generalization performance on unseen data while training is performed on the remaining 80%."
   ],
   "id": "8ae62095d0e0d9a4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c23955a408e86",
   "metadata": {},
   "outputs": [],
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build Model\n",
    "\n",
    "Construct a fully connected feedforward neural network with:\n",
    "\n",
    "- Input Layer: Size matches the number of features\n",
    "\n",
    "- Hidden Layers: Two dense layers (128 and 64 units) with ReLU activation and L2 regularization\n",
    "\n",
    "- Dropout: 50% to prevent overfitting\n",
    "\n",
    "- Output Layer: Softmax with units equal to the number of labels\n",
    "\n",
    "Compile using `adam` optimizer and categorical cross-entropy loss."
   ],
   "id": "88c0a70ea4b562f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b67c5f5de71c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(unique_labels), activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train Model\n",
    "\n",
    "Training is done with early stopping to avoid overfitting:\n",
    "\n",
    "- `monitor='val_loss'` ensures we stop when validation performance plateaus.\n",
    "\n",
    "- `restore_best_weights=True` rolls back to the best epoch.\n",
    "\n",
    "Validation split of 20% ensures the model is evaluated on unseen data during training."
   ],
   "id": "7d0cc57e118cd962"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f983550697084f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Save Model and Labels\n",
    "\n",
    "Save the trained Keras model and the sorted list of labels.\n",
    "This allows the same model to be loaded for inference and ensures labels remain consistent."
   ],
   "id": "b83a16c23ce5c5a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aaf66621871bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_PATH)\n",
    "print(\"Model saved.\")\n",
    "\n",
    "with open(LABELS_PATH, \"w\") as f:\n",
    "    json.dump(unique_labels, f)\n",
    "print(\"Label order saved.\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Convert to CoreML\n",
    "\n",
    "Optionally, convert the Keras model to CoreML for deployment on iOS devices.\n",
    "We specify dynamic batch size using `ct.RangeDim()` and set minimum deployment target to iOS 14. This prepares the model for mobile applications."
   ],
   "id": "d0d3b3259917b487"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aabf165366d23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model = ct.convert(\n",
    "    model,\n",
    "    source=\"tensorflow\",\n",
    "    inputs=[ct.TensorType(shape=(ct.RangeDim(), X_train.shape[1]))],\n",
    "    minimum_deployment_target=ct.target.iOS14\n",
    ")\n",
    "coreml_model.save(COREML_PATH)\n",
    "print(\"CoreML model saved.\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluate Model\n",
    "\n",
    "Finally, evaluate the trained model on the test set to report the final loss and accuracy.\n",
    "This provides an unbiased estimate of the modelâ€™s predictive performance."
   ],
   "id": "1e163a09c6465700"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a9f249488341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Evaluation - Loss: {loss:.4f}, Accuracy: {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
